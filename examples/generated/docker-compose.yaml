# Generated by openapi-operator-gen v0.0.10-6-gad62e9c-dirty
# Docker Compose for petstore Operator Development
#
# Usage:
#   # Build the operator image
#   docker compose build operator
#
#   # Run with k3s (lightweight Kubernetes cluster in Docker)
#   docker compose --profile k3s up -d
#
#   # Access k3s from host (kubeconfig is copied to ./k3s-output/)
#   KUBECONFIG=./k3s-output/kubeconfig.yaml kubectl get nodes
#
#   # Run operator with local kubeconfig (kind/minikube)
#   docker compose --profile with-k8s up -d
#
#   # Deploy operator inside k3s as Kubernetes workloads
#   docker compose --profile k3s-deploy up -d
#   KUBECONFIG=./k3s-deploy-output/kubeconfig.yaml kubectl get pods -n petstore-system
#
#   # Rundeck is included in k3s-deploy profile (port 4440)
#   open http://localhost:4440   # Login: admin / admin

services:
  petstore:
    image: docker.io/swaggerapi/petstore3:unstable
    profiles:
      - k3s
      - with-k8s
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/api/v3/openapi.json"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Lightweight Kubernetes cluster using k3s
  k3s:
    image: rancher/k3s:v1.29.0-k3s1
    command: server --disable traefik --disable servicelb --disable metrics-server --tls-san k3s
    privileged: true
    profiles:
      - k3s
    ports:
      - "6443:6443"
    environment:
      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml
      - K3S_KUBECONFIG_MODE=666
    volumes:
      - k3s-data:/var/lib/rancher/k3s
      - k3s-kubeconfig:/output
    healthcheck:
      test: ["CMD", "kubectl", "get", "nodes"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 30s

  # Fix kubeconfig and apply CRDs to k3s cluster
  k3s-init:
    image: bitnami/kubectl:latest
    user: root
    profiles:
      - k3s
    volumes:
      - k3s-kubeconfig:/kubeconfig
      - ./config/crd/bases:/crds:ro
      - ./k3s-output:/host-output
    environment:
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for kubeconfig..."
        until [ -f /kubeconfig/kubeconfig.yaml ]; do sleep 1; done
        echo "Fixing kubeconfig server address for container access..."
        sed 's/127.0.0.1/k3s/g' /kubeconfig/kubeconfig.yaml > /kubeconfig/kubeconfig-fixed.yaml
        chmod 644 /kubeconfig/kubeconfig-fixed.yaml
        echo "Copying kubeconfig for host access..."
        cp /kubeconfig/kubeconfig.yaml /host-output/kubeconfig.yaml
        chmod 644 /host-output/kubeconfig.yaml
        echo "Waiting for k3s API..."
        until kubectl get nodes; do sleep 2; done
        echo "Applying CRDs..."
        kubectl apply -f /crds/
        echo "CRDs applied successfully"
        sleep infinity
    depends_on:
      k3s:
        condition: service_healthy

  # The operator container - connects to k3s
  operator-k3s:
    build:
      context: .
      dockerfile: Dockerfile
    image: petstore-operator:local
    profiles:
      - k3s
    environment:
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
      - OPERATOR_LOG_LEVEL=debug
      - REST_API_BASE_URL=http://petstore:8080/api/v3
    volumes:
      - k3s-kubeconfig:/kubeconfig:ro
    depends_on:
      petstore:
        condition: service_healthy
      k3s-init:
        condition: service_started

  # The operator container - connects to local Kubernetes cluster
  operator:
    build:
      context: .
      dockerfile: Dockerfile
    image: petstore-operator:local
    profiles:
      - with-k8s
    environment:
      - KUBECONFIG=/root/.kube/config
      - REST_API_BASE_URL=http://petstore:8080/api/v3
    volumes:
      - ${HOME}/.kube:/root/.kube:ro
    depends_on:
      petstore:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ============================================================================
  # k3s-deploy profile: Deploy operator INSIDE k3s as Kubernetes workloads
  # ============================================================================

  # k3s cluster for in-cluster deployment
  k3s-deploy:
    image: rancher/k3s:v1.29.0-k3s1
    command: server --disable traefik --disable servicelb --disable metrics-server --tls-san k3s-deploy
    privileged: true
    profiles:
      - k3s-deploy
    ports:
      - "6445:6443"
    environment:
      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml
      - K3S_KUBECONFIG_MODE=666
    volumes:
      - k3s-deploy-data:/var/lib/rancher/k3s
      - k3s-deploy-kubeconfig:/output
      - k3s-deploy-images:/images
      - k3s-deploy-run:/run/k3s
    healthcheck:
      test: ["CMD", "kubectl", "get", "nodes"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 30s

  # Build operator image and save as tarball for k3s import
  k3s-deploy-image-save:
    image: docker:cli
    profiles:
      - k3s-deploy
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - k3s-deploy-images:/images
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Saving petstore-operator:local image as tarball..."
        until docker image inspect petstore-operator:local >/dev/null 2>&1; do
          echo "Waiting for petstore-operator:local image to be built..."
          sleep 2
        done
        docker save petstore-operator:local -o /images/operator.tar
        echo "Saving docker.io/swaggerapi/petstore3:unstable image as tarball..."
        docker pull docker.io/swaggerapi/petstore3:unstable
        docker save docker.io/swaggerapi/petstore3:unstable -o /images/target-api.tar
        echo "Downloading helm binary..."
        wget -q https://get.helm.sh/helm-v3.14.0-linux-amd64.tar.gz -O /tmp/helm.tar.gz
        tar -xzf /tmp/helm.tar.gz -C /tmp
        cp /tmp/linux-amd64/helm /images/helm
        chmod +x /images/helm
        echo "Images and tools saved successfully"
    depends_on:
      k3s-deploy-operator-build:
        condition: service_completed_successfully

  # Build the operator image
  k3s-deploy-operator-build:
    build:
      context: .
      dockerfile: Dockerfile
    image: petstore-operator:local
    profiles:
      - k3s-deploy
    entrypoint: ["/manager", "--version"]

  # Import images into k3s and deploy all workloads
  k3s-deploy-init:
    image: rancher/k3s:v1.29.0-k3s1
    profiles:
      - k3s-deploy
    network_mode: "service:k3s-deploy"
    volumes:
      - k3s-deploy-kubeconfig:/kubeconfig
      - k3s-deploy-images:/images:ro
      - k3s-deploy-run:/run/k3s:ro
      - ./chart/petstore:/chart/petstore:ro
      - ./config/target-api:/manifests:ro
      - ./k3s-deploy-output:/host-output
    environment:
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=== k3s-deploy-init: Setting up in-cluster deployment ==="

        echo "Waiting for kubeconfig..."
        until [ -f /kubeconfig/kubeconfig.yaml ]; do sleep 1; done

        echo "Fixing kubeconfig for container access..."
        cp /kubeconfig/kubeconfig.yaml /kubeconfig/kubeconfig-fixed.yaml
        chmod 644 /kubeconfig/kubeconfig-fixed.yaml

        echo "Copying kubeconfig for host access (port 6445)..."
        sed 's/6443/6445/g' /kubeconfig/kubeconfig.yaml > /host-output/kubeconfig.yaml
        chmod 644 /host-output/kubeconfig.yaml

        echo "Waiting for k3s API..."
        until kubectl get nodes; do sleep 2; done

        echo "--- Importing container images into k3s ---"
        until [ -f /images/operator.tar ]; do
          echo "Waiting for image tarballs..."
          sleep 2
        done
        echo "Waiting for containerd socket..."
        until [ -S /run/k3s/containerd/containerd.sock ]; do
          echo "  socket not ready yet..."
          sleep 2
        done
        echo "Importing operator image..."
        ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io images import /images/operator.tar
        echo "Importing target API image..."
        ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io images import /images/target-api.tar
        echo "Images imported successfully"

        echo "--- Installing Helm ---"
        cp /images/helm /bin/helm
        helm version

        echo "--- Creating namespace ---"
        kubectl create namespace petstore-system

        echo "--- Deploying target API ---"
        kubectl apply -f /manifests/deployment.yaml

        echo "--- Installing operator via Helm chart ---"
        helm install petstore /chart/petstore \
          -n petstore-system \
          --set controllerManager.manager.image.repository=docker.io/library/petstore-operator \
          --set controllerManager.manager.image.tag=local \
          --set controllerManager.manager.imagePullPolicy=Never \
          --set 'controllerManager.manager.args={--leader-elect,--namespace-scoped,--deployment-name=petstore,--base-path=/api/v3}'

        echo "--- Waiting for target API to be ready ---"
        kubectl rollout status deployment/petstore -n petstore-system --timeout=120s

        echo "--- Waiting for operator to be ready ---"
        kubectl rollout status deployment/petstore-controller-manager -n petstore-system --timeout=120s

        echo "=== All workloads deployed successfully ==="
        echo "Access the cluster:"
        echo "  KUBECONFIG=./k3s-deploy-output/kubeconfig.yaml kubectl get pods -n petstore-system"
    depends_on:
      k3s-deploy:
        condition: service_healthy
      k3s-deploy-image-save:
        condition: service_completed_successfully

  # ============================================================================
  # Rundeck: Run operator jobs via web UI (k3s-deploy profile)
  # ============================================================================

  # Rundeck server with API token for automated setup
  rundeck:
    image: rundeck/rundeck:5.8.0
    profiles:
      - k3s-deploy
    ports:
      - "4440:4440"
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        mkdir -p /tmp/remco-partials/framework
        echo "rundeck.tokens.file=/home/rundeck/etc/tokens.properties" > /tmp/remco-partials/framework/tokens.properties
        export PATH="/home/rundeck/server/data:$PATH"
        export KUBECONFIG="/home/rundeck/server/data/kube/config"
        exec /home/rundeck/docker-lib/entry.sh
    environment:
      - PATH=/home/rundeck/server/data:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
      - KUBECONFIG=/home/rundeck/server/data/kube/config
      - RUNDECK_GRAILS_URL=http://localhost:4440
      - RUNDECK_DATABASE_DRIVER=org.h2.Driver
      - RUNDECK_DATABASE_URL=jdbc:h2:file:/home/rundeck/server/data/grailsdb;DB_CLOSE_ON_EXIT=FALSE;NON_KEYWORDS=MONTH,HOUR,MINUTE,YEAR
    volumes:
      - rundeck-data:/home/rundeck/server/data
      - ./rundeck-project/tokens.properties:/home/rundeck/etc/tokens.properties:ro
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:4440"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 60s
    depends_on:
      k3s-deploy-init:
        condition: service_completed_successfully

  # Build the kubectl plugin binary for linux/amd64
  rundeck-kubectl-build:
    image: golang:1.25
    profiles:
      - k3s-deploy
    volumes:
      - ./kubectl-plugin:/src:ro
      - rundeck-plugin-bin:/output
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Building kubectl plugin..."
        cp -r /src /build
        cd /build
        go mod tidy
        CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -o /output/kubectl-petstore .
        chmod +x /output/kubectl-petstore
        echo "kubectl plugin built successfully"

  # Configure Rundeck: install kubectl + plugin, create project, import jobs
  rundeck-init:
    image: bitnami/kubectl:latest
    user: root
    profiles:
      - k3s-deploy
    volumes:
      - k3s-deploy-kubeconfig:/kubeconfig:ro
      - rundeck-plugin-bin:/plugin-bin:ro
      - ./rundeck-project:/rundeck-project:ro
      - rundeck-data:/rundeck-data
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "=== rundeck-init: Configuring Rundeck ==="

        RUNDECK_URL="http://rundeck:4440"
        TOKEN="letmein99"

        echo "--- Waiting for Rundeck API ---"
        until curl -sf -H "Accept: application/json" \
          -H "X-Rundeck-Auth-Token: $${TOKEN}" \
          "$${RUNDECK_URL}/api/14/system/info" 2>/dev/null | grep -q '"system"'; do
          echo "  Rundeck not ready yet..."
          sleep 5
        done
        echo "Rundeck API is ready"

        echo "--- Creating project: petstore-operator ---"
        curl -sf -X POST \
          -H "Accept: application/json" \
          -H "Content-Type: application/json" \
          -H "X-Rundeck-Auth-Token: $${TOKEN}" \
          -d '{"name":"petstore-operator","description":"Manage petstore resources via Kubernetes operator","config":{"project.name":"petstore-operator"}}' \
          "$${RUNDECK_URL}/api/14/projects" || echo "Project may already exist"

        echo "--- Importing job definitions ---"
        for jobfile in /rundeck-project/jobs/resources/*.yaml \
                       /rundeck-project/jobs/queries/*.yaml \
                       /rundeck-project/jobs/actions/*.yaml \
                       /rundeck-project/jobs/operations/*.yaml; do
          if [ -f "$$jobfile" ]; then
            jobname=$$(basename "$$jobfile")
            echo "  Importing $${jobname}..."
            curl -sf -X POST \
              -H "Accept: application/json" \
              -H "Content-Type: application/yaml" \
              -H "X-Rundeck-Auth-Token: $${TOKEN}" \
              --data-binary @"$$jobfile" \
              "$${RUNDECK_URL}/api/14/project/petstore-operator/jobs/import?format=yaml&dupeOption=update" || echo "  Warning: failed to import $${jobname}"
          fi
        done

        echo "--- Installing kubectl and plugin into Rundeck ---"
        cp $$(which kubectl) /rundeck-data/kubectl
        chmod +x /rundeck-data/kubectl
        echo "kubectl binary staged"
        if [ -f /plugin-bin/kubectl-petstore ]; then
          cp /plugin-bin/kubectl-petstore /rundeck-data/kubectl-petstore
          chmod +x /rundeck-data/kubectl-petstore
          echo "Plugin binary staged"
        else
          echo "Warning: kubectl plugin binary not found"
        fi

        echo "--- Preparing kubeconfig for Rundeck ---"
        mkdir -p /rundeck-data/kube
        sed 's/127.0.0.1/k3s-deploy/g' /kubeconfig/kubeconfig.yaml > /rundeck-data/kube/config
        chmod 644 /rundeck-data/kube/config
        echo "Kubeconfig written to /rundeck-data/kube/config"

        echo "=== Rundeck setup complete ==="
        echo "Access Rundeck at: http://localhost:4440"
        echo "Default credentials: admin / admin"
    depends_on:
      rundeck:
        condition: service_healthy
      rundeck-kubectl-build:
        condition: service_completed_successfully

volumes:
  k3s-data:
  k3s-kubeconfig:
  k3s-deploy-data:
  k3s-deploy-kubeconfig:
  k3s-deploy-images:
  k3s-deploy-run:
  rundeck-data:
  rundeck-plugin-bin:
