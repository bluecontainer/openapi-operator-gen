# Docker Compose for Petstore API + Operator Development
#
# This compose file runs the Swagger Petstore API and optionally the operator
# for local development and testing.
#
# Usage:
#   # Start only the petstore API
#   docker compose up -d petstore
#
#   # Build the operator image
#   docker compose build operator
#
#   # Run with k3s (lightweight Kubernetes cluster in Docker)
#   docker compose --profile k3s up -d
#
#   # Access k3s from host (kubeconfig is copied to ./k3s-output/)
#   KUBECONFIG=./k3s-output/kubeconfig.yaml kubectl get nodes
#
#   # Run operator with local kubeconfig (kind/minikube)
#   docker compose --profile with-k8s up -d
#
#   # Run with two petstore instances (multi-endpoint fan-out testing)
#   docker compose --profile multi-endpoint up -d
#
#   # For local development without Docker:
#   cd examples/generated
#   go run ./cmd/manager --base-url=http://localhost:8080/api/v3
#
# Note: The 'k3s' profile provides a lightweight Kubernetes cluster in Docker.
# For connecting to an existing cluster, use 'with-k8s' with kind or minikube.
# The 'multi-endpoint' profile runs two petstore instances for testing baseURLs fan-out.

services:
  petstore:
    image: swaggerapi/petstore3:unstable
    profiles:
      - k3s
      - with-k8s
    ports:
      - "8080:8080"
    environment:
      - SWAGGER_HOST=http://localhost:8080
      - SWAGGER_URL=http://localhost:8080
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/api/v3/openapi.json"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Lightweight Kubernetes cluster using k3s
  # Provides a full Kubernetes API without the overhead of kind/minikube
  k3s:
    image: rancher/k3s:v1.29.0-k3s1
    command: server --disable traefik --disable servicelb --disable metrics-server --tls-san k3s
    privileged: true
    profiles:
      - k3s
    ports:
      - "6443:6443"
    environment:
      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml
      - K3S_KUBECONFIG_MODE=666
    volumes:
      - k3s-data:/var/lib/rancher/k3s
      - k3s-kubeconfig:/output
    healthcheck:
      test: ["CMD", "kubectl", "get", "nodes"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 30s

  # Fix kubeconfig and apply CRDs to k3s cluster
  k3s-init:
    image: bitnami/kubectl:latest
    user: root
    profiles:
      - k3s
    volumes:
      - k3s-kubeconfig:/kubeconfig
      - ./generated/config/crd/bases:/crds:ro
      - ./k3s-output:/host-output
    environment:
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for kubeconfig..."
        until [ -f /kubeconfig/kubeconfig.yaml ]; do sleep 1; done
        echo "Fixing kubeconfig server address for container access..."
        sed 's/127.0.0.1/k3s/g' /kubeconfig/kubeconfig.yaml > /kubeconfig/kubeconfig-fixed.yaml
        chmod 644 /kubeconfig/kubeconfig-fixed.yaml
        echo "Copying kubeconfig for host access..."
        cp /kubeconfig/kubeconfig.yaml /host-output/kubeconfig.yaml
        chmod 644 /host-output/kubeconfig.yaml
        echo "Waiting for k3s API..."
        until kubectl get nodes; do sleep 2; done
        echo "Applying CRDs..."
        kubectl apply -f /crds/
        echo "CRDs applied successfully"
        sleep infinity
    depends_on:
      k3s:
        condition: service_healthy

  # The operator container - connects to k3s
  operator-k3s:
    build:
      context: ..
      dockerfile: examples/Dockerfile.operator
    image: petstore-operator:local
    profiles:
      - k3s
    environment:
      - REST_API_BASE_URL=http://petstore:8080/api/v3
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
      - OPERATOR_LOG_LEVEL=debug
    volumes:
      - k3s-kubeconfig:/kubeconfig:ro
    depends_on:
      petstore:
        condition: service_healthy
      k3s-init:
        condition: service_started

  # The operator container - connects to local Kubernetes cluster
  operator:
    build:
      context: ..
      dockerfile: examples/Dockerfile.operator
    image: petstore-operator:local
    profiles:
      - with-k8s
    environment:
      - REST_API_BASE_URL=http://petstore:8080/api/v3
      - KUBECONFIG=/root/.kube/config
    volumes:
      # Mount kubeconfig for local Kubernetes access (kind/minikube)
      - ${HOME}/.kube:/root/.kube:ro
    depends_on:
      petstore:
        condition: service_healthy
    # For kind clusters, the API server is on the host network
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # ============================================================================
  # Multi-endpoint profile: Two petstore instances for testing baseURLs fan-out
  # ============================================================================

  # First petstore instance (port 8081)
  petstore-1:
    image: swaggerapi/petstore3:unstable
    profiles:
      - multi-endpoint
    ports:
      - "8081:8080"
    environment:
      - SWAGGER_HOST=http://localhost:8081
      - SWAGGER_URL=http://localhost:8081
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/api/v3/openapi.json"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Second petstore instance (port 8082)
  petstore-2:
    image: swaggerapi/petstore3:unstable
    profiles:
      - multi-endpoint
    ports:
      - "8082:8080"
    environment:
      - SWAGGER_HOST=http://localhost:8082
      - SWAGGER_URL=http://localhost:8082
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8080/api/v3/openapi.json"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # k3s for multi-endpoint testing
  k3s-multi:
    image: rancher/k3s:v1.29.0-k3s1
    command: server --disable traefik --disable servicelb --disable metrics-server --tls-san k3s-multi
    privileged: true
    profiles:
      - multi-endpoint
    ports:
      - "6444:6443"
    environment:
      - K3S_KUBECONFIG_OUTPUT=/output/kubeconfig.yaml
      - K3S_KUBECONFIG_MODE=666
    volumes:
      - k3s-multi-data:/var/lib/rancher/k3s
      - k3s-multi-kubeconfig:/output
    healthcheck:
      test: ["CMD", "kubectl", "get", "nodes"]
      interval: 10s
      timeout: 5s
      retries: 12
      start_period: 30s

  # Initialize k3s for multi-endpoint
  k3s-multi-init:
    image: bitnami/kubectl:latest
    user: root
    profiles:
      - multi-endpoint
    volumes:
      - k3s-multi-kubeconfig:/kubeconfig
      - ./generated/config/crd/bases:/crds:ro
      - ./k3s-multi-output:/host-output
    environment:
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo "Waiting for kubeconfig..."
        until [ -f /kubeconfig/kubeconfig.yaml ]; do sleep 1; done
        echo "Fixing kubeconfig server address for container access..."
        sed 's/127.0.0.1/k3s-multi/g' /kubeconfig/kubeconfig.yaml > /kubeconfig/kubeconfig-fixed.yaml
        chmod 644 /kubeconfig/kubeconfig-fixed.yaml
        echo "Copying kubeconfig for host access (use port 6444)..."
        sed 's/6443/6444/g' /kubeconfig/kubeconfig.yaml > /host-output/kubeconfig.yaml
        chmod 644 /host-output/kubeconfig.yaml
        echo "Waiting for k3s API..."
        until kubectl get nodes; do sleep 2; done
        echo "Applying CRDs..."
        kubectl apply -f /crds/
        echo "CRDs applied successfully"
        sleep infinity
    depends_on:
      k3s-multi:
        condition: service_healthy

  # Operator configured with two base URLs for fan-out testing
  # Uses REST_API_BASE_URLS to configure global fan-out to both petstore instances.
  # Writes will be sent to ALL URLs, reads use first successful response.
  operator-multi:
    build:
      context: ..
      dockerfile: examples/Dockerfile.operator
    image: petstore-operator:local
    profiles:
      - multi-endpoint
    environment:
      # Global fan-out to both petstore instances (comma-separated)
      - REST_API_BASE_URLS=http://petstore-1:8080/api/v3,http://petstore-2:8080/api/v3
      - KUBECONFIG=/kubeconfig/kubeconfig-fixed.yaml
      - OPERATOR_LOG_LEVEL=debug
    volumes:
      - k3s-multi-kubeconfig:/kubeconfig:ro
    depends_on:
      petstore-1:
        condition: service_healthy
      petstore-2:
        condition: service_healthy
      k3s-multi-init:
        condition: service_started

volumes:
  k3s-data:
  k3s-kubeconfig:
  k3s-multi-data:
  k3s-multi-kubeconfig:
